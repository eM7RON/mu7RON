{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# mu7RON Demo 3\n",
    "---\n",
    "\n",
    "In this notebook we will see how to generate music from an RNN that we have trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import midi\n",
    "\n",
    "from mu7ron import maps, temporal, coders, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the same parameters that you used when you processed the input data and trained the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vocab:  288\n"
     ]
    }
   ],
   "source": [
    "off_mode     = False   # whether to encode NoteOffEvents or just NoteOnEvents with 0 velocity\n",
    "q            = 8       # quantization factor of velocity\n",
    "q_map        = maps.create_q_map(128, q, encode=True, decode=True)\n",
    "t            = 8     # the smallest timestep in milliseconds\n",
    "n_vel        = utils.dynamic_order(128, q) # No. of different available levels of velocity\n",
    "n_time       = 144   # Available timesteps\n",
    "n_pitch      = 128 * 2 if off_mode else 128 # + Available pitches\n",
    "n_pulse      = 0     # Number of added pulses\n",
    "n_vocab      = n_time + n_pitch + n_vel + n_pulse # Available choices\n",
    "n_sample     = 24    # batch size\n",
    "n_input      = 120   # time steps - the temporal dimension\n",
    "n_output     = 1     # number of timesteps to predict into the future\n",
    "n_teach      = 12\n",
    "n_step       = n_sample\n",
    "n_example    = 1\n",
    "buffer       = 150\n",
    "random_state = 117   # \"Wake Me... When You Need Me.\"\n",
    "\n",
    "time_encoder = temporal.timeslips_encoder #temporal.base_digits_encoder #temporal.timeslips_encoder\n",
    "time_decoder = temporal.timeslips_decoder # temporal.base_digits_decoder #temporal.timeslips_decoder\n",
    "ekwa         = dict(t=t, n_time=n_time) # dict(b=n_time) #dict(t=t, n_time=n_time)\n",
    "dkwa         = dict(t=t) # dict(b=n_time) #dict(t=t)\n",
    "print('n_vocab: ', n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idealy you should have saved these; a good idea is to pickle them and load them up like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.path.join('mu7ron', 'data', 'models', 'model4', 'params_train_valid.pkl')\n",
    "\n",
    "with open(WORKING_DIR, 'rb') as file:\n",
    "    params, train, valid = pickle.load(file)\n",
    "    for name, value in params.items():\n",
    "        if name.startswith('time_'):\n",
    "            value = f\"temporal.{str(value).split(' ')[1]}\"\n",
    "        exec(f'{name} = {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have saved my training data as a 3-tuple of parameters, training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out sequences that are too short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = [sequence for sequence in train if len(sequence) >= n_input]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select a random sample from the validation set to act as a seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = valid[np.random.randint(len(valid))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can listen to the seed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.play(\n",
    "    coders.decategorize_output_with_drums(\n",
    "        seed,\n",
    "        q=q,\n",
    "        q_map=q_map,\n",
    "        n_time=n_time,\n",
    "        off_mode=off_mode,\n",
    "        drm_mode=drm_mode,\n",
    "        time_decoder=time_decoder,\n",
    "        dkwa=dkwa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need an n_input length section of the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 510)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(len(seed) - n_input)\n",
    "one_hot_seed = np.zeros((n_input, n_vocab))\n",
    "one_hot_seed[range(n_input), seed[n :n + n_input]] = 1.\n",
    "one_hot_seed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to generate some music. We just need to know the path of a pretrained model.  \n",
    "\n",
    "Here we are going to use beam search: https://en.wikipedia.org/wiki/Beam_search  \n",
    "\n",
    "A values of 5-10 are quite normal for the beam_width. As the beam_width is increased the algorithm becomes\n",
    "quite computationally heavy so it is worth keeping it around these values. Plus my implementation, at the moment, will fill up all available memory if you set it to generate a long enough sequence. It is worth taking this into account.\n",
    "\n",
    "`coders.beam_search` will return a `beam` object which is a python list containing 2-element lists where the first element is a probability and element 2 is the one_hot encoded sequence we have generated.\n",
    "\n",
    "The last element in `beam` (beam[-1]) will contain the most likely sequence. The sequences still require converting into valid midi sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 999/999 [01:45<00:00,  9.46it/s]\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_MODEL = os.path.join('mu7ron', 'data', 'models', 'model4', 'model_0_5604430437088013_13_Oct_2020_08-38-40.h5')\n",
    "\n",
    "beam_width = 10\n",
    "song_length = 1000\n",
    "\n",
    "beam = coders.beam_search(one_hot_seed, beam_width, path_to_model=PATH_TO_MODEL, n_iter=song_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 1.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])],\n",
       " [0.018919766,\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 1.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])],\n",
       " [0.047428966,\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 1.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])],\n",
       " [0.047429442,\n",
       "  array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 1.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]])]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now listen to the generated music!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_song = coders.decategorize_output_with_drums(np.argmax(beam[-1][1][n_input:], axis=1), \n",
    "                    q=q,\n",
    "                    q_map=q_map,\n",
    "                    n_time=n_time,\n",
    "                    off_mode=off_mode,\n",
    "                    drm_mode=drm_mode,\n",
    "                    time_decoder=time_decoder, \n",
    "                    dkwa=dkwa)\n",
    "utils.play(my_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some midi players may need additional midi.events objects added in order to play the sequence but for a bare minimum we should at the very least add a midi.EndOfTrackEvent()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_song = edit.finalize_midi_sequence(my_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets save the song for safe keeping :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_OF_SONG  = 'my_song.mid'\n",
    "WHERE_TO_SAVE = os.path.join(os.getcwd(), NAME_OF_SONG)\n",
    "\n",
    "midi.write_midifile(WHERE_TO_SAVE, my_song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFV",
   "language": "python",
   "name": "tfv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
